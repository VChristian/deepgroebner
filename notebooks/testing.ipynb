{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepgroebner.pg import PPOAgent\n",
    "from deepgroebner.networks import ParallelMultilayerPerceptron\n",
    "from deepgroebner.ideals import FixedIdealGenerator\n",
    "from deepgroebner.buchberger import BuchbergerEnv, LeadMonomialsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the list of polynomials using SymPy, and then construct a `BuchbergerEnv` which always starts with the given list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, x, y, z = sp.ring('x,y,z', sp.FF(32003), 'grevlex')\n",
    "F = [x + y + z, x*y + y*z + x*z, x*y*z - 1]\n",
    "ideal_gen = FixedIdealGenerator(F)\n",
    "env = BuchbergerEnv(ideal_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the environment yourself using the `reset` and `step` methods. The `step` method takes in a choice of one of the available pairs, and returns a tuple of `(next_state, reward, done, info)`. This follows the interface of [OpenAI Gym](https://gym.openai.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([x + y + z, x*y + x*z + y*z, x*y*z + 32002 mod 32003], {(0, 1), (0, 2)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([x + y + z, x*y + x*z + y*z, x*y*z + 32002 mod 32003, y**2 + y*z + z**2],\n",
       "  {(0, 2)}),\n",
       " -2,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([x + y + z,\n",
       "   x*y + x*z + y*z,\n",
       "   x*y*z + 32002 mod 32003,\n",
       "   y**2 + y*z + z**2,\n",
       "   z**3 + 32002 mod 32003],\n",
       "  set()),\n",
       " -2,\n",
       " True,\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step((0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find where you saved the weights of a previously trained model. Make sure `n` (the number of variables), `k` (the number of lead monomials visible), and `policy_hl` (the size of hidden layers in the network) are all the same as in training.\n",
    "\n",
    "The current `run.py` script saves the weights in subdirectories of `data/runs/` that are named from the date and a hash of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "k = 2\n",
    "policy_hl = [128]\n",
    "\n",
    "# replace with your saved policy weights file\n",
    "filename = \"../data/runs/run1/policy-50.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these numbers fixed, we can construct the agent and and wrapped environment that it can act on (the state of the wrapped environment is a matrix with rows corresponding to each pair, and an action is a choice of row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_env = LeadMonomialsWrapper(env, k=k)\n",
    "network = ParallelMultilayerPerceptron(2 * k * n, policy_hl)\n",
    "agent = PPOAgent(network)\n",
    "agent.load_policy_weights(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the environments `reset` and `step` methods as above, and the agent's `act` method, which returns the agent's choice of action, to step through a computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = wrapped_env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = agent.act(state)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1]]), -1, False, {})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = wrapped_env.step(action)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view the state of the original unwrapped environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([x + y + z,\n",
       "  x*y + x*z + y*z,\n",
       "  x*y*z + 32002 mod 32003,\n",
       "  y**2*z + y*z**2 + 1 mod 32003],\n",
       " {(0, 1)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_env.env.G, wrapped_env.env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
